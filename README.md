# FAD-Net: Frequency-domain Amplitude-Phase Decoupling Network for Optical-Elevation Remote Sensing Segmentation

This repository contains the official implementation of **FAD-Net** (Frequency-domain Amplitude-Phase Decoupling Network). FAD-Net is designed for the semantic segmentation of multi-modal remote sensing images (Optical + Elevation).

It introduces two key components:
1.  **MM-Mona Module:** Addresses heterogeneous feature misalignment by decoupling amplitude and phase in the frequency domain.
2.  **APRP Decoder:** A decoder that resolves mutual interference between deep semantics and shallow details using phase-geometric constraints.

## ğŸ› ï¸ Environment Setup

To run this project, you need a Python environment with PyTorch installed. It is recommended to use **Python 3.8+** and **PyTorch 2.10+**.

You can install the required dependencies using pip:

```bash
pip install -r requirements.txt
```


## ğŸ“‚ Ensure your project directory matches the following structure:

```text
FAD-Net/
â”œâ”€â”€ config.py
â”œâ”€â”€ train.py
â”œâ”€â”€ model/
â”œâ”€â”€ datasets/
â”‚Â  Â â”œâ”€â”€ Vaihingen/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ top/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ dsm/
â”‚Â  Â â”‚Â  Â â””â”€â”€ ground_truth/
â”‚Â  Â â””â”€â”€ Potsdam/
â”‚Â  Â  Â  Â â”œâ”€â”€ top/
â”‚Â  Â  Â  Â â”œâ”€â”€ dsm/
â”‚Â  Â  Â  Â â””â”€â”€ ground_truth/
â”œâ”€â”€ pretrained_weights/
â”œâ”€â”€ model_weights/
â””â”€â”€ logs/
```

---

## ğŸ’¾ Supported Datasets: ISPRS Vaihingen and Potsdam.

1. **Download Data:**
Please refer to the **MMSegmentation Dataset Preparation Guide** to download the raw data:
ğŸ‘‰ **[Download ISPRS Datasets Here](https://github.com/open-mmlab/mmsegmentation/blob/main/docs/en/user_guides/2_dataset_prepare.md#prepare-datasets)**
2. **Organize Data:**
After downloading, you must extract and rename/move the files to match the `FILE_TEMPLATES` in `config.py`.
* **Vaihingen:** Ensure images are named like `top_mosaic_09cm_area1.tif`.
* **Potsdam:** Ensure images are named like `top_potsdam_2_10_RGB.tif`.


*Note: The script expects specific subfolders (`top`, `dsm`, `ground_truth`). Please ensure your extracted files are moved into these folders inside `datasets/Vaihingen` or `datasets/Potsdam`.*

---

## ğŸ‹ï¸ Pretrained Weights & Configuration

ğŸ‘‰ **[Download Swin-V2 Weights (Microsoft GitHub)](https://github.com/microsoft/Swin-Transformer)**

Download the Swin Transformer V2 weights and place them in the `pretrained_weights/` folder. Update `config.py` according to your selected backbone:

### Swin-V2 Base

```python
'PRETRAINED_WEIGHTS_PATH': 'pretrained_weights/swinv2_base_patch4_window12_192_22k.pth',

'SWINV2': {
    'EMBED_DIM': 128,              
    'DEPTHS': [2, 2, 18, 2],       
    'NUM_HEADS': [4, 8, 16, 32],   
    'WINDOW_SIZE': 16,             
    'PRETRAINED_WINDOW_SIZES': [12, 12, 12, 6], 
}

```

### Swin-V2 Small

```python
'PRETRAINED_WEIGHTS_PATH': 'pretrained_weights/swinv2_small_patch4_window16_256.pth',

'SWINV2': {
    'EMBED_DIM': 96,             
    'DEPTHS': [2, 2, 18, 2],     
    'NUM_HEADS': [3, 6, 12, 24],   
    'WINDOW_SIZE': 16,
    'PRETRAINED_WINDOW_SIZES': [16, 16, 16, 8], 
}

```

---

## ğŸš€ Run the training script for your desired dataset:

**Train on Potsdam:**

```bash
python train.py --dataset potsdam

```

**Train on Vaihingen:**

```bash
python train.py --dataset vaihingen

```
